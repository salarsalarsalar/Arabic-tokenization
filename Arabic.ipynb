{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afa2cea7",
   "metadata": {},
   "source": [
    "# Arabic grammar word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab46440-93c1-480d-981d-51a5e3bda834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of كَتَبَ:\n",
      "Pattern: {'type': 'regular', 'pattern': 'فَعَلَ', 'forms': {'past': 'فَعَلَ', 'present': 'يَفْعَلُ', 'masdar': 'فَعْل'}}\n",
      "\n",
      "Possible cases:\n",
      "\n",
      "RAFA:\n",
      "  singular: كَتَبَُ\n",
      "  dual: كَتَبََانِ\n",
      "  plural_masc: كَتَبَُونَ\n",
      "  plural_fem: كَتَبََاتُ\n",
      "\n",
      "NASB:\n",
      "  singular: كَتَبََ\n",
      "  dual: كَتَبََيْنِ\n",
      "  plural_masc: كَتَبَِينَ\n",
      "  plural_fem: كَتَبََاتِ\n",
      "\n",
      "JARR:\n",
      "  singular: كَتَبَِ\n",
      "  dual: كَتَبََيْنِ\n",
      "  plural_masc: كَتَبَِينَ\n",
      "  plural_fem: كَتَبََاتِ\n"
     ]
    }
   ],
   "source": [
    "class ArabicMorphologicalAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Basic patterns (أوزان) for trilateral roots\n",
    "        self.patterns = {\n",
    "            'regular': {\n",
    "                'فَعَلَ': {'past': 'فَعَلَ', 'present': 'يَفْعَلُ', 'masdar': 'فَعْل'},\n",
    "                'فَعِلَ': {'past': 'فَعِلَ', 'present': 'يَفْعَلُ', 'masdar': 'فَعَل'},\n",
    "                'فَعُلَ': {'past': 'فَعُلَ', 'present': 'يَفْعُلُ', 'masdar': 'فُعْل'},\n",
    "                'فَعَّلَ': {'past': 'فَعَّلَ', 'present': 'يُفَعِّلُ', 'masdar': 'تَفْعِيل'},\n",
    "                'فَاعَلَ': {'past': 'فَاعَلَ', 'present': 'يُفَاعِلُ', 'masdar': 'مُفَاعَلَة'},\n",
    "                'أَفْعَلَ': {'past': 'أَفْعَلَ', 'present': 'يُفْعِلُ', 'masdar': 'إِفْعَال'},\n",
    "                'تَفَعَّلَ': {'past': 'تَفَعَّلَ', 'present': 'يَتَفَعَّلُ', 'masdar': 'تَفَعُّل'},\n",
    "                'تَفَاعَلَ': {'past': 'تَفَاعَلَ', 'present': 'يَتَفَاعَلُ', 'masdar': 'تَفَاعُل'},\n",
    "                'اِنْفَعَلَ': {'past': 'اِنْفَعَلَ', 'present': 'يَنْفَعِلُ', 'masdar': 'اِنْفِعَال'},\n",
    "                'اِفْتَعَلَ': {'past': 'اِفْتَعَلَ', 'present': 'يَفْتَعِلُ', 'masdar': 'اِفْتِعَال'}\n",
    "            },\n",
    "            'irregular': {\n",
    "                'hollow': {\n",
    "                    'قَالَ': {'past': 'قَالَ', 'present': 'يَقُولُ', 'masdar': 'قَوْل'},\n",
    "                    'بَاعَ': {'past': 'بَاعَ', 'present': 'يَبِيعُ', 'masdar': 'بَيْع'}\n",
    "                },\n",
    "                'hamzated': {\n",
    "                    'أَكَلَ': {'past': 'أَكَلَ', 'present': 'يَأْكُلُ', 'masdar': 'أَكْل'},\n",
    "                    'سَأَلَ': {'past': 'سَأَلَ', 'present': 'يَسْأَلُ', 'masdar': 'سُؤَال'}\n",
    "                },\n",
    "                'doubled': {\n",
    "                    'مَدَّ': {'past': 'مَدَّ', 'present': 'يَمُدُّ', 'masdar': 'مَدّ'},\n",
    "                    'فَرَّ': {'past': 'فَرَّ', 'present': 'يَفِرُّ', 'masdar': 'فِرَار'}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Case endings (إعراب)\n",
    "        self.case_endings = {\n",
    "            'rafa': {\n",
    "                'singular': 'ُ',\n",
    "                'dual': 'َانِ',\n",
    "                'plural_masc': 'ُونَ',\n",
    "                'plural_fem': 'َاتُ'\n",
    "            },\n",
    "            'nasb': {\n",
    "                'singular': 'َ',\n",
    "                'dual': 'َيْنِ',\n",
    "                'plural_masc': 'ِينَ',\n",
    "                'plural_fem': 'َاتِ'\n",
    "            },\n",
    "            'jarr': {\n",
    "                'singular': 'ِ',\n",
    "                'dual': 'َيْنِ',\n",
    "                'plural_masc': 'ِينَ',\n",
    "                'plural_fem': 'َاتِ'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Pronouns and their conjugations\n",
    "        self.pronouns = {\n",
    "            'singular': {\n",
    "                'first': 'أَنَا',\n",
    "                'second_masc': 'أَنْتَ',\n",
    "                'second_fem': 'أَنْتِ',\n",
    "                'third_masc': 'هُوَ',\n",
    "                'third_fem': 'هِيَ'\n",
    "            },\n",
    "            'dual': {\n",
    "                'second': 'أَنْتُمَا',\n",
    "                'third_masc': 'هُمَا',\n",
    "                'third_fem': 'هُمَا'\n",
    "            },\n",
    "            'plural': {\n",
    "                'first': 'نَحْنُ',\n",
    "                'second_masc': 'أَنْتُمْ',\n",
    "                'second_fem': 'أَنْتُنَّ',\n",
    "                'third_masc': 'هُمْ',\n",
    "                'third_fem': 'هُنَّ'\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def get_pattern(self, word: str) -> dict:\n",
    "        \"\"\"\n",
    "        Identify the morphological pattern of a given word\n",
    "        \"\"\"\n",
    "        # Check regular patterns\n",
    "        for pattern, forms in self.patterns['regular'].items():\n",
    "            if self._matches_pattern(word, pattern):\n",
    "                return {'type': 'regular', 'pattern': pattern, 'forms': forms}\n",
    "        \n",
    "        # Check irregular patterns\n",
    "        for irreg_type, patterns in self.patterns['irregular'].items():\n",
    "            for pattern, forms in patterns.items():\n",
    "                if self._matches_pattern(word, pattern):\n",
    "                    return {'type': 'irregular', 'subtype': irreg_type, 'pattern': pattern, 'forms': forms}\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def _matches_pattern(self, word: str, pattern: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if a word matches a given pattern\n",
    "        \"\"\"\n",
    "        # Remove diacritics for comparison\n",
    "        word_clean = self._remove_diacritics(word)\n",
    "        pattern_clean = self._remove_diacritics(pattern)\n",
    "        \n",
    "        if len(word_clean) != len(pattern_clean):\n",
    "            return False\n",
    "            \n",
    "        # Extract root letters from pattern (typically ف ع ل)\n",
    "        root_positions = [i for i, char in enumerate(pattern_clean) \n",
    "                         if char in 'فعل']\n",
    "        \n",
    "        # Check if the word follows the pattern structure\n",
    "        return all(word_clean[i] == pattern_clean[i] \n",
    "                  for i in range(len(pattern_clean)) \n",
    "                  if i not in root_positions)\n",
    "\n",
    "    def add_case_ending(self, word: str, case: str, number: str) -> str:\n",
    "        \"\"\"\n",
    "        Add the appropriate case ending to a word\n",
    "        \"\"\"\n",
    "        if case not in self.case_endings or number not in self.case_endings[case]:\n",
    "            return word\n",
    "        \n",
    "        return word + self.case_endings[case][number]\n",
    "\n",
    "    def conjugate(self, root: str, pattern: str, pronoun: str) -> str:\n",
    "        \"\"\"\n",
    "        Conjugate a verb according to its pattern and pronoun\n",
    "        \"\"\"\n",
    "        if pattern not in self.patterns['regular']:\n",
    "            return None\n",
    "            \n",
    "        pattern_forms = self.patterns['regular'][pattern]\n",
    "        \n",
    "        # Basic conjugation logic (simplified)\n",
    "        if pronoun in self.pronouns['singular']:\n",
    "            return pattern_forms['present']  # This is simplified\n",
    "        elif pronoun in self.pronouns['dual']:\n",
    "            return pattern_forms['present'] + 'ان'\n",
    "        elif pronoun in self.pronouns['plural']:\n",
    "            return pattern_forms['present'] + 'ون'\n",
    "            \n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove_diacritics(text: str) -> str:\n",
    "        \"\"\"\n",
    "        Remove Arabic diacritical marks from text\n",
    "        \"\"\"\n",
    "        diacritics = ['َ', 'ُ', 'ِ', 'ّ', 'ْ', 'ً', 'ٌ', 'ٍ']\n",
    "        return ''.join(char for char in text if char not in diacritics)\n",
    "\n",
    "    def analyze_word(self, word: str) -> dict:\n",
    "        \"\"\"\n",
    "        Perform complete morphological analysis of a word\n",
    "        \"\"\"\n",
    "        analysis = {\n",
    "            'original': word,\n",
    "            'without_diacritics': self._remove_diacritics(word),\n",
    "            'pattern': self.get_pattern(word),\n",
    "            'possible_cases': {}\n",
    "        }\n",
    "        \n",
    "        # Add possible case endings\n",
    "        for case in self.case_endings:\n",
    "            analysis['possible_cases'][case] = {\n",
    "                'singular': self.add_case_ending(word, case, 'singular'),\n",
    "                'dual': self.add_case_ending(word, case, 'dual'),\n",
    "                'plural_masc': self.add_case_ending(word, case, 'plural_masc'),\n",
    "                'plural_fem': self.add_case_ending(word, case, 'plural_fem')\n",
    "            }\n",
    "            \n",
    "        return analysis\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = ArabicMorphologicalAnalyzer()\n",
    "    \n",
    "    # Example analysis\n",
    "    word = \"كَتَبَ\"\n",
    "    analysis = analyzer.analyze_word(word)\n",
    "    print(f\"Analysis of {word}:\")\n",
    "    print(f\"Pattern: {analysis['pattern']}\")\n",
    "    print(\"\\nPossible cases:\")\n",
    "    for case, forms in analysis['possible_cases'].items():\n",
    "        print(f\"\\n{case.upper()}:\")\n",
    "        for number, form in forms.items():\n",
    "            print(f\"  {number}: {form}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b4b409",
   "metadata": {},
   "source": [
    "# Word and sentences analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4d2cdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Analysis for 'يَكْتُبُ':\n",
      "Features: {'case': 'rafa', 'tense': 'present', 'number': 'singular', 'gender': 'masculine'}\n",
      "Rankings: {'case': 3, 'tense': 2, 'number': 1, 'gender': 1}\n",
      "Total Rank: 7\n",
      "\n",
      "Phrase Analysis for 'الكتابُ الجديدُ':\n",
      "Phrase Type: verbal_phrase\n",
      "Total Rank: 14\n",
      "\n",
      "Sentence Analysis for 'كَتَبَ الطالبُ الدرسَ':\n",
      "Word Count: 3\n",
      "Total Rank: 21\n"
     ]
    }
   ],
   "source": [
    "class ArabicMorphologicalAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Previous initializations remain (patterns, case_endings, pronouns)\n",
    "        # Adding ranking points for different features\n",
    "        self.rank_points = {\n",
    "            'case': {\n",
    "                'rafa': 3,    # مرفوع\n",
    "                'nasb': 2,    # منصوب\n",
    "                'jarr': 1     # مجرور\n",
    "            },\n",
    "            'tense': {\n",
    "                'past': 1,    # ماضي\n",
    "                'present': 2, # مضارع\n",
    "                'future': 3   # مستقبل\n",
    "            },\n",
    "            'number': {\n",
    "                'singular': 1, # مفرد\n",
    "                'dual': 2,    # مثنى\n",
    "                'plural': 3   # جمع\n",
    "            },\n",
    "            'gender': {\n",
    "                'masculine': 1, # مذكر\n",
    "                'feminine': 2  # مؤنث\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Adding markers for different features\n",
    "        self.markers = {\n",
    "            'future': 'س',  # Future marker س\n",
    "            'dual_markers': ['ان', 'ين'],\n",
    "            'plural_markers': {\n",
    "                'masculine': ['ون', 'ين'],\n",
    "                'feminine': ['ات']\n",
    "            },\n",
    "            'feminine_markers': ['ة', 'ى', 'اء']\n",
    "        }\n",
    "        \n",
    "        # Previous patterns, case_endings, and pronouns code remains here...\n",
    "\n",
    "    def analyze_sentence(self, sentence: str) -> dict:\n",
    "        \"\"\"\n",
    "        Analyze a complete sentence with rankings for each word\n",
    "        \"\"\"\n",
    "        words = sentence.split()\n",
    "        analysis = {\n",
    "            'full_sentence': sentence,\n",
    "            'word_count': len(words),\n",
    "            'words': [],\n",
    "            'total_rank': 0\n",
    "        }\n",
    "        \n",
    "        for word in words:\n",
    "            word_analysis = self.analyze_word_comprehensive(word)\n",
    "            analysis['words'].append(word_analysis)\n",
    "            analysis['total_rank'] += word_analysis['total_rank']\n",
    "            \n",
    "        return analysis\n",
    "\n",
    "    def analyze_word_comprehensive(self, word: str) -> dict:\n",
    "        \"\"\"\n",
    "        Comprehensive word analysis with ranking points\n",
    "        \"\"\"\n",
    "        analysis = {\n",
    "            'word': word,\n",
    "            'features': {\n",
    "                'case': self._determine_case(word),\n",
    "                'tense': self._determine_tense(word),\n",
    "                'number': self._determine_number(word),\n",
    "                'gender': self._determine_gender(word)\n",
    "            },\n",
    "            'rankings': {},\n",
    "            'total_rank': 0\n",
    "        }\n",
    "        \n",
    "        # Calculate rankings for each feature\n",
    "        for feature, value in analysis['features'].items():\n",
    "            if value in self.rank_points[feature]:\n",
    "                rank = self.rank_points[feature][value]\n",
    "                analysis['rankings'][feature] = rank\n",
    "                analysis['total_rank'] += rank\n",
    "        \n",
    "        return analysis\n",
    "\n",
    "    def _determine_case(self, word: str) -> str:\n",
    "        \"\"\"\n",
    "        Determine the grammatical case of a word\n",
    "        \"\"\"\n",
    "        word = self._remove_diacritics(word)\n",
    "        \n",
    "        # Case determination rules\n",
    "        if word.endswith('ُ') or word.endswith('ُن') or word.endswith('ون'):\n",
    "            return 'rafa'\n",
    "        elif word.endswith('َ') or word.endswith('ًا') or word.endswith('ين'):\n",
    "            return 'nasb'\n",
    "        elif word.endswith('ِ') or word.endswith('ٍ'):\n",
    "            return 'jarr'\n",
    "        \n",
    "        # Default case based on position and context would go here\n",
    "        return 'rafa'  # Default case\n",
    "\n",
    "    def _determine_tense(self, word: str) -> str:\n",
    "        \"\"\"\n",
    "        Determine the tense of a word\n",
    "        \"\"\"\n",
    "        # Remove diacritics for easier matching\n",
    "        word = self._remove_diacritics(word)\n",
    "        \n",
    "        # Future tense check\n",
    "        if word.startswith('س') or word.startswith('سوف'):\n",
    "            return 'future'\n",
    "            \n",
    "        # Present tense markers (ي، ت، أ، ن)\n",
    "        present_markers = ['ي', 'ت', 'أ', 'ن']\n",
    "        if any(word.startswith(marker) for marker in present_markers):\n",
    "            return 'present'\n",
    "            \n",
    "        # Past tense typically ends with appropriate suffixes\n",
    "        past_endings = ['ت', 'تما', 'تم', 'تن', 'نا']\n",
    "        if any(word.endswith(ending) for ending in past_endings):\n",
    "            return 'past'\n",
    "            \n",
    "        return 'present'  # Default tense\n",
    "\n",
    "    def _determine_number(self, word: str) -> str:\n",
    "        \"\"\"\n",
    "        Determine if word is singular, dual, or plural\n",
    "        \"\"\"\n",
    "        word = self._remove_diacritics(word)\n",
    "        \n",
    "        # Check dual markers\n",
    "        if any(word.endswith(marker) for marker in self.markers['dual_markers']):\n",
    "            return 'dual'\n",
    "            \n",
    "        # Check plural markers\n",
    "        if (any(word.endswith(marker) for marker in self.markers['plural_markers']['masculine']) or\n",
    "            any(word.endswith(marker) for marker in self.markers['plural_markers']['feminine'])):\n",
    "            return 'plural'\n",
    "            \n",
    "        return 'singular'  # Default number\n",
    "\n",
    "    def _determine_gender(self, word: str) -> str:\n",
    "        \"\"\"\n",
    "        Determine if word is masculine or feminine\n",
    "        \"\"\"\n",
    "        word = self._remove_diacritics(word)\n",
    "        \n",
    "        # Check feminine markers\n",
    "        if any(word.endswith(marker) for marker in self.markers['feminine_markers']):\n",
    "            return 'feminine'\n",
    "            \n",
    "        return 'masculine'  # Default gender\n",
    "\n",
    "    def analyze_phrase(self, phrase: str) -> dict:\n",
    "        \"\"\"\n",
    "        Analyze a phrase (smaller than sentence) with context\n",
    "        \"\"\"\n",
    "        words = phrase.split()\n",
    "        analysis = {\n",
    "            'phrase': phrase,\n",
    "            'word_count': len(words),\n",
    "            'words': [],\n",
    "            'phrase_type': self._determine_phrase_type(words),\n",
    "            'total_rank': 0\n",
    "        }\n",
    "        \n",
    "        for i, word in enumerate(words):\n",
    "            word_analysis = self.analyze_word_comprehensive(word)\n",
    "            # Add contextual analysis based on position in phrase\n",
    "            word_analysis['position'] = self._analyze_position(i, len(words))\n",
    "            analysis['words'].append(word_analysis)\n",
    "            analysis['total_rank'] += word_analysis['total_rank']\n",
    "            \n",
    "        return analysis\n",
    "\n",
    "    def _determine_phrase_type(self, words: list) -> str:\n",
    "        \"\"\"\n",
    "        Determine the type of phrase (nominal or verbal)\n",
    "        \"\"\"\n",
    "        if not words:\n",
    "            return 'unknown'\n",
    "            \n",
    "        first_word = self._remove_diacritics(words[0])\n",
    "        \n",
    "        # Check if phrase starts with a verb\n",
    "        if self._determine_tense(first_word) in ['past', 'present', 'future']:\n",
    "            return 'verbal_phrase'\n",
    "            \n",
    "        return 'nominal_phrase'\n",
    "\n",
    "    def _analyze_position(self, index: int, total_words: int) -> str:\n",
    "        \"\"\"\n",
    "        Analyze word position in phrase/sentence\n",
    "        \"\"\"\n",
    "        if index == 0:\n",
    "            return 'initial'\n",
    "        elif index == total_words - 1:\n",
    "            return 'final'\n",
    "        else:\n",
    "            return 'middle'\n",
    "\n",
    "    def get_total_score(self, text: str) -> dict:\n",
    "        \"\"\"\n",
    "        Get comprehensive score for text (word/phrase/sentence)\n",
    "        \"\"\"\n",
    "        words = text.split()\n",
    "        if len(words) == 1:\n",
    "            return self.analyze_word_comprehensive(text)\n",
    "        elif len(words) <= 3:\n",
    "            return self.analyze_phrase(text)\n",
    "        else:\n",
    "            return self.analyze_sentence(text)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _remove_diacritics(text: str) -> str:\n",
    "        \"\"\"\n",
    "        Remove Arabic diacritical marks from text\n",
    "        \"\"\"\n",
    "        diacritics = ['َ', 'ُ', 'ِ', 'ّ', 'ْ', 'ً', 'ٌ', 'ٍ']\n",
    "        return ''.join(char for char in text if char not in diacritics)\n",
    "\n",
    "    def analyze_word(self, word: str) -> dict:\n",
    "        \"\"\"\n",
    "        Perform complete morphological analysis of a word\n",
    "        \"\"\"\n",
    "        analysis = {\n",
    "            'original': word,\n",
    "            'without_diacritics': self._remove_diacritics(word),\n",
    "            'pattern': self.get_pattern(word),\n",
    "            'possible_cases': {}\n",
    "        }\n",
    "        \n",
    "        # Add possible case endings\n",
    "        for case in self.case_endings:\n",
    "            analysis['possible_cases'][case] = {\n",
    "                'singular': self.add_case_ending(word, case, 'singular'),\n",
    "                'dual': self.add_case_ending(word, case, 'dual'),\n",
    "                'plural_masc': self.add_case_ending(word, case, 'plural_masc'),\n",
    "                'plural_fem': self.add_case_ending(word, case, 'plural_fem')\n",
    "            }\n",
    "            \n",
    "        return analysis\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = ArabicMorphologicalAnalyzer()\n",
    "    \n",
    "    # Example analyses\n",
    "    word = \"يَكْتُبُ\"  # Present tense, masculine, singular\n",
    "    phrase = \"الكتابُ الجديدُ\"  # Nominal phrase\n",
    "    sentence = \"كَتَبَ الطالبُ الدرسَ\"  # Verbal sentence\n",
    "    \n",
    "    # Single word analysis\n",
    "    word_analysis = analyzer.get_total_score(word)\n",
    "    print(f\"\\nWord Analysis for '{word}':\")\n",
    "    print(f\"Features: {word_analysis['features']}\")\n",
    "    print(f\"Rankings: {word_analysis['rankings']}\")\n",
    "    print(f\"Total Rank: {word_analysis['total_rank']}\")\n",
    "    \n",
    "    # Phrase analysis\n",
    "    phrase_analysis = analyzer.get_total_score(phrase)\n",
    "    print(f\"\\nPhrase Analysis for '{phrase}':\")\n",
    "    print(f\"Phrase Type: {phrase_analysis['phrase_type']}\")\n",
    "    print(f\"Total Rank: {phrase_analysis['total_rank']}\")\n",
    "    \n",
    "    # Sentence analysis\n",
    "    sentence_analysis = analyzer.get_total_score(sentence)\n",
    "    print(f\"\\nSentence Analysis for '{sentence}':\")\n",
    "    print(f\"Word Count: {sentence_analysis['word_count']}\")\n",
    "    print(f\"Total Rank: {sentence_analysis['total_rank']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f1279",
   "metadata": {},
   "source": [
    "# Token generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b66e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ArabicTokenGenerator:\n",
    "#     def __init__(self):\n",
    "#         # Token types with their respective features\n",
    "#         self.token_types = {\n",
    "#             'WORD': 1,\n",
    "#             'PUNCTUATION': 2,\n",
    "#             'NUMBER': 3,\n",
    "#             'SYMBOL': 4\n",
    "#         }\n",
    "        \n",
    "#         # Token features based on grammatical rules\n",
    "#         self.token_features = {\n",
    "#             'case': ['rafa', 'nasb', 'jarr'],\n",
    "#             'tense': ['past', 'present', 'future'],\n",
    "#             'number': ['singular', 'dual', 'plural'],\n",
    "#             'gender': ['masculine', 'feminine']\n",
    "#         }\n",
    "        \n",
    "#         # Special characters and their token types\n",
    "#         self.special_chars = {\n",
    "#             '.': 'PUNCTUATION',\n",
    "#             '،': 'PUNCTUATION',\n",
    "#             '؟': 'PUNCTUATION',\n",
    "#             '!': 'PUNCTUATION',\n",
    "#             '@': 'SYMBOL',\n",
    "#             '#': 'SYMBOL'\n",
    "#         }\n",
    "\n",
    "# class ArabicMorphologicalAnalyzer:\n",
    "#     def __init__(self):\n",
    "#         # Previous initializations remain...\n",
    "#         self.token_generator = ArabicTokenGenerator()\n",
    "        \n",
    "#         # Token position markers\n",
    "#         self.position_markers = {\n",
    "#             'START': 'S',\n",
    "#             'MIDDLE': 'M',\n",
    "#             'END': 'E',\n",
    "#             'SINGLE': 'SI'\n",
    "#         }\n",
    "\n",
    "#     def generate_tokens(self, text: str) -> list:\n",
    "#         \"\"\"\n",
    "#         Generate tokens for given text based on morphological rules\n",
    "#         \"\"\"\n",
    "#         analysis = self.get_total_score(text)\n",
    "#         tokens = []\n",
    "        \n",
    "#         if isinstance(analysis['words'], list):\n",
    "#             # For phrases and sentences\n",
    "#             for i, word_analysis in enumerate(analysis['words']):\n",
    "#                 token = self._create_token(word_analysis, i, len(analysis['words']))\n",
    "#                 tokens.append(token)\n",
    "#         else:\n",
    "#             # For single words\n",
    "#             tokens.append(self._create_token(analysis, 0, 1))\n",
    "            \n",
    "#         return tokens\n",
    "\n",
    "#     def _create_token(self, word_analysis: dict, position: int, total_words: int) -> dict:\n",
    "#         \"\"\"\n",
    "#         Create a token with all relevant features\n",
    "#         \"\"\"\n",
    "#         # Generate unique token ID\n",
    "#         token_id = self._generate_token_id(word_analysis['word'], position)\n",
    "        \n",
    "#         # Determine position marker\n",
    "#         position_marker = self._get_position_marker(position, total_words)\n",
    "        \n",
    "#         return {\n",
    "#             'token_id': token_id,\n",
    "#             'word': word_analysis['word'],\n",
    "#             'features': word_analysis['features'],\n",
    "#             'position': position_marker,\n",
    "#             'rank': word_analysis['total_rank'],\n",
    "#             'type': self._determine_token_type(word_analysis['word']),\n",
    "#             'metadata': {\n",
    "#                 'position_index': position,\n",
    "#                 'total_positions': total_words,\n",
    "#                 'normalized_form': self._normalize_word(word_analysis['word'])\n",
    "#             }\n",
    "#         }\n",
    "\n",
    "#     def _generate_token_id(self, word: str, position: int) -> str:\n",
    "#         \"\"\"\n",
    "#         Generate unique token ID based on word and position\n",
    "#         \"\"\"\n",
    "#         normalized_word = self._normalize_word(word)\n",
    "#         return f\"TK_{normalized_word}_{position}\"\n",
    "\n",
    "#     def _get_position_marker(self, position: int, total_words: int) -> str:\n",
    "#         \"\"\"\n",
    "#         Determine position marker for token\n",
    "#         \"\"\"\n",
    "#         if total_words == 1:\n",
    "#             return self.position_markers['SINGLE']\n",
    "#         elif position == 0:\n",
    "#             return self.position_markers['START']\n",
    "#         elif position == total_words - 1:\n",
    "#             return self.position_markers['END']\n",
    "#         else:\n",
    "#             return self.position_markers['MIDDLE']\n",
    "\n",
    "#     def _determine_token_type(self, word: str) -> str:\n",
    "#         \"\"\"\n",
    "#         Determine token type based on word characteristics\n",
    "#         \"\"\"\n",
    "#         if word in self.token_generator.special_chars:\n",
    "#             return self.token_generator.special_chars[word]\n",
    "#         elif word.isdigit():\n",
    "#             return 'NUMBER'\n",
    "#         else:\n",
    "#             return 'WORD'\n",
    "\n",
    "#     def generate_sentence_tokens(self, sentence: str) -> list:\n",
    "#         \"\"\"\n",
    "#         Generate tokens for a complete sentence with context\n",
    "#         \"\"\"\n",
    "#         words = sentence.split()\n",
    "#         tokens = []\n",
    "        \n",
    "#         for i, word in enumerate(words):\n",
    "#             # Get word analysis\n",
    "#             word_analysis = self.analyze_word_comprehensive(word)\n",
    "            \n",
    "#             # Create base token\n",
    "#             token = self._create_token(word_analysis, i, len(words))\n",
    "            \n",
    "#             # Add contextual information\n",
    "#             token['context'] = {\n",
    "#                 'previous': words[i-1] if i > 0 else None,\n",
    "#                 'next': words[i+1] if i < len(words)-1 else None,\n",
    "#                 'sentence_position': self._get_sentence_position(i, len(words))\n",
    "#             }\n",
    "            \n",
    "#             tokens.append(token)\n",
    "            \n",
    "#         return tokens\n",
    "\n",
    "#     def _get_sentence_position(self, index: int, total_words: int) -> str:\n",
    "#         \"\"\"\n",
    "#         Get detailed sentence position information\n",
    "#         \"\"\"\n",
    "#         if total_words <= 1:\n",
    "#             return 'COMPLETE'\n",
    "#         elif index == 0:\n",
    "#             return 'BEGINNING'\n",
    "#         elif index == total_words - 1:\n",
    "#             return 'END'\n",
    "#         else:\n",
    "#             return f'MIDDLE_{index}/{total_words}'\n",
    "\n",
    "#     def _normalize_word(self, word: str) -> str:\n",
    "#         \"\"\"\n",
    "#         Normalize word for token ID generation\n",
    "#         \"\"\"\n",
    "#         # Remove diacritics and special characters\n",
    "#         normalized = self._remove_diacritics(word)\n",
    "#         # Replace spaces and special characters\n",
    "#         normalized = normalized.replace(' ', '_')\n",
    "#         return normalized\n",
    "\n",
    "#     def tokenize_text(self, text: str) -> dict:\n",
    "#         \"\"\"\n",
    "#         Complete tokenization of text with analysis\n",
    "#         \"\"\"\n",
    "#         return {\n",
    "#             'original_text': text,\n",
    "#             'tokens': self.generate_tokens(text),\n",
    "#             'token_count': len(text.split()),\n",
    "#             'analysis': self.get_total_score(text),\n",
    "#             'metadata': {\n",
    "#                 'has_punctuation': any(char in text for char in self.token_generator.special_chars),\n",
    "#                 'normalized_text': self._normalize_word(text)\n",
    "#             }\n",
    "#         }\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     analyzer = ArabicMorphologicalAnalyzer()\n",
    "    \n",
    "#     # Example text\n",
    "#     word = \"يَكْتُبُ\"\n",
    "#     phrase = \"الكتابُ الجديدُ\"\n",
    "#     sentence = \"كَتَبَ الطالبُ الدرسَ\"\n",
    "    \n",
    "#     # Generate tokens for different text types\n",
    "#     word_tokens = analyzer.tokenize_text(word)\n",
    "#     phrase_tokens = analyzer.tokenize_text(phrase)\n",
    "#     sentence_tokens = analyzer.tokenize_text(sentence)\n",
    "    \n",
    "#     # Print results\n",
    "#     print(\"\\nWord Tokens:\")\n",
    "#     print(word_tokens)\n",
    "    \n",
    "#     print(\"\\nPhrase Tokens:\")\n",
    "#     print(phrase_tokens)\n",
    "    \n",
    "#     print(\"\\nSentence Tokens:\")\n",
    "#     print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab6657e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Analysis:\n",
      "{'original_text': 'يَكْتُبُ', 'word_count': 1, 'analysis_type': 'word', 'morphological_analysis': [{'word': 'يَكْتُبُ', 'pattern': None, 'features': {'case': 'rafa', 'tense': 'present', 'number': 'singular', 'gender': 'masculine'}, 'root': 'يكتب'}], 'tokens': [{'token_id': 'TK_يكتب_0', 'word': 'يَكْتُبُ', 'type': 1, 'position': 'SI', 'features': {'case': 'rafa', 'tense': 'present', 'number': 'singular', 'gender': 'masculine'}}], 'total_rank': 7, 'metadata': {'normalized_text': 'يكتب', 'has_diacritics': True}}\n",
      "\n",
      "Phrase Analysis:\n",
      "{'original_text': 'الكتابُ الجديدُ', 'word_count': 2, 'analysis_type': 'phrase', 'morphological_analysis': [{'word': 'الكتابُ', 'pattern': None, 'features': {'case': 'rafa', 'tense': 'past', 'number': 'singular', 'gender': 'masculine'}, 'root': 'كتاب'}, {'word': 'الجديدُ', 'pattern': None, 'features': {'case': 'rafa', 'tense': 'past', 'number': 'singular', 'gender': 'masculine'}, 'root': 'جديد'}], 'tokens': [{'token_id': 'TK_الكتاب_0', 'word': 'الكتابُ', 'type': 1, 'position': 'S', 'features': {'case': 'rafa', 'tense': 'past', 'number': 'singular', 'gender': 'masculine'}}, {'token_id': 'TK_الجديد_1', 'word': 'الجديدُ', 'type': 1, 'position': 'E', 'features': {'case': 'rafa', 'tense': 'past', 'number': 'singular', 'gender': 'masculine'}}], 'total_rank': 12, 'metadata': {'normalized_text': 'الكتاب الجديد', 'has_diacritics': True}}\n",
      "\n",
      "Sentence Analysis:\n",
      "{'original_text': 'كَتَبَ الطالبُ الدرسَ', 'word_count': 3, 'analysis_type': 'phrase', 'morphological_analysis': [{'word': 'كَتَبَ', 'pattern': {'type': 'regular', 'pattern': 'فَعَلَ', 'forms': {'past': 'فَعَلَ', 'present': 'يَفْعَلُ', 'masdar': 'فَعْل'}}, 'features': {'case': 'rafa', 'tense': 'past', 'number': 'singular', 'gender': 'masculine'}, 'root': 'كتب'}, {'word': 'الطالبُ', 'pattern': None, 'features': {'case': 'rafa', 'tense': 'past', 'number': 'singular', 'gender': 'masculine'}, 'root': 'طالب'}, {'word': 'الدرسَ', 'pattern': None, 'features': {'case': 'rafa', 'tense': 'past', 'number': 'singular', 'gender': 'masculine'}, 'root': 'درس'}], 'tokens': [{'token_id': 'TK_كتب_0', 'word': 'كَتَبَ', 'type': 1, 'position': 'S', 'features': {'case': 'rafa', 'tense': 'past', 'number': 'singular', 'gender': 'masculine'}}, {'token_id': 'TK_الطالب_1', 'word': 'الطالبُ', 'type': 1, 'position': 'M', 'features': {'case': 'rafa', 'tense': 'past', 'number': 'singular', 'gender': 'masculine'}}, {'token_id': 'TK_الدرس_2', 'word': 'الدرسَ', 'type': 1, 'position': 'E', 'features': {'case': 'rafa', 'tense': 'past', 'number': 'singular', 'gender': 'masculine'}}], 'total_rank': 18, 'metadata': {'normalized_text': 'كتب الطالب الدرس', 'has_diacritics': True}}\n"
     ]
    }
   ],
   "source": [
    "class UnifiedArabicAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Patterns (أوزان) for trilateral roots\n",
    "        self.patterns = {\n",
    "            'regular': {\n",
    "                'فَعَلَ': {'past': 'فَعَلَ', 'present': 'يَفْعَلُ', 'masdar': 'فَعْل'},\n",
    "                'فَعِلَ': {'past': 'فَعِلَ', 'present': 'يَفْعَلُ', 'masdar': 'فَعَل'},\n",
    "                'فَعُلَ': {'past': 'فَعُلَ', 'present': 'يَفْعُلُ', 'masdar': 'فُعْل'},\n",
    "                'فَعَّلَ': {'past': 'فَعَّلَ', 'present': 'يُفَعِّلُ', 'masdar': 'تَفْعِيل'},\n",
    "                'فَاعَلَ': {'past': 'فَاعَلَ', 'present': 'يُفَاعِلُ', 'masdar': 'مُفَاعَلَة'}\n",
    "            },\n",
    "            'irregular': {\n",
    "                'hollow': {\n",
    "                    'قَالَ': {'past': 'قَالَ', 'present': 'يَقُولُ', 'masdar': 'قَوْل'},\n",
    "                    'بَاعَ': {'past': 'بَاعَ', 'present': 'يَبِيعُ', 'masdar': 'بَيْع'}\n",
    "                },\n",
    "                'hamzated': {\n",
    "                    'أَكَلَ': {'past': 'أَكَلَ', 'present': 'يَأْكُلُ', 'masdar': 'أَكْل'},\n",
    "                    'سَأَلَ': {'past': 'سَأَلَ', 'present': 'يَسْأَلُ', 'masdar': 'سُؤَال'}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Ranking points for different features\n",
    "        self.rank_points = {\n",
    "            'case': {'rafa': 3, 'nasb': 2, 'jarr': 1},\n",
    "            'tense': {'future': 3, 'present': 2, 'past': 1},\n",
    "            'number': {'plural': 3, 'dual': 2, 'singular': 1},\n",
    "            'gender': {'feminine': 2, 'masculine': 1}\n",
    "        }\n",
    "        \n",
    "        # Token types and markers\n",
    "        self.token_types = {\n",
    "            'WORD': 1,\n",
    "            'PUNCTUATION': 2,\n",
    "            'NUMBER': 3,\n",
    "            'SYMBOL': 4\n",
    "        }\n",
    "        \n",
    "        # Position markers\n",
    "        self.position_markers = {\n",
    "            'START': 'S',\n",
    "            'MIDDLE': 'M',\n",
    "            'END': 'E',\n",
    "            'SINGLE': 'SI'\n",
    "        }\n",
    "        \n",
    "        # Feature markers\n",
    "        self.markers = {\n",
    "            'future': 'س',\n",
    "            'dual_markers': ['ان', 'ين'],\n",
    "            'plural_markers': {\n",
    "                'masculine': ['ون', 'ين'],\n",
    "                'feminine': ['ات']\n",
    "            },\n",
    "            'feminine_markers': ['ة', 'ى', 'اء']\n",
    "        }\n",
    "\n",
    "    def analyze(self, text: str) -> dict:\n",
    "        \"\"\"\n",
    "        Unified analysis method that combines morphological analysis, ranking, and tokenization\n",
    "        \"\"\"\n",
    "        words = text.split()\n",
    "        \n",
    "        result = {\n",
    "            'original_text': text,\n",
    "            'word_count': len(words),\n",
    "            'analysis_type': self._determine_analysis_type(words),\n",
    "            'morphological_analysis': [],\n",
    "            'tokens': [],\n",
    "            'total_rank': 0,\n",
    "            'metadata': {\n",
    "                'normalized_text': self._normalize_text(text),\n",
    "                'has_diacritics': self._has_diacritics(text)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Analyze each word\n",
    "        for i, word in enumerate(words):\n",
    "            word_analysis = self._analyze_word(word, i, len(words))\n",
    "            result['morphological_analysis'].append(word_analysis['morphology'])\n",
    "            result['tokens'].append(word_analysis['token'])\n",
    "            result['total_rank'] += word_analysis['rank']\n",
    "            \n",
    "        return result\n",
    "\n",
    "    def _analyze_word(self, word: str, position: int, total_words: int) -> dict:\n",
    "        \"\"\"\n",
    "        Comprehensive word analysis including morphology, ranking, and tokenization\n",
    "        \"\"\"\n",
    "        # Morphological analysis\n",
    "        morphology = {\n",
    "            'word': word,\n",
    "            'pattern': self._get_pattern(word),\n",
    "            'features': self._get_features(word),\n",
    "            'root': self._extract_root(word)\n",
    "        }\n",
    "        \n",
    "        # Calculate rank\n",
    "        features = morphology['features']\n",
    "        rank = sum(self.rank_points[feature][value] \n",
    "                  for feature, value in features.items() \n",
    "                  if feature in self.rank_points and value in self.rank_points[feature])\n",
    "        \n",
    "        # Generate token\n",
    "        token = {\n",
    "            'token_id': f\"TK_{self._normalize_text(word)}_{position}\",\n",
    "            'word': word,\n",
    "            'type': self._determine_token_type(word),\n",
    "            'position': self._get_position_marker(position, total_words),\n",
    "            'features': features\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'morphology': morphology,\n",
    "            'token': token,\n",
    "            'rank': rank\n",
    "        }\n",
    "\n",
    "    def _get_features(self, word: str) -> dict:\n",
    "        \"\"\"\n",
    "        Extract all grammatical features from a word\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'case': self._determine_case(word),\n",
    "            'tense': self._determine_tense(word),\n",
    "            'number': self._determine_number(word),\n",
    "            'gender': self._determine_gender(word)\n",
    "        }\n",
    "\n",
    "    def _determine_case(self, word: str) -> str:\n",
    "        \"\"\"\n",
    "        Determine grammatical case\n",
    "        \"\"\"\n",
    "        word = self._remove_diacritics(word)\n",
    "        if word.endswith(('ُ', 'ُن', 'ون')):\n",
    "            return 'rafa'\n",
    "        elif word.endswith(('َ', 'ًا', 'ين')):\n",
    "            return 'nasb'\n",
    "        elif word.endswith(('ِ', 'ٍ')):\n",
    "            return 'jarr'\n",
    "        return 'rafa'\n",
    "\n",
    "    def _determine_tense(self, word: str) -> str:\n",
    "        \"\"\"\n",
    "        Determine verb tense\n",
    "        \"\"\"\n",
    "        if word.startswith(self.markers['future']):\n",
    "            return 'future'\n",
    "        elif any(word.startswith(m) for m in ['ي', 'ت', 'أ', 'ن']):\n",
    "            return 'present'\n",
    "        return 'past'\n",
    "\n",
    "    def _determine_number(self, word: str) -> str:\n",
    "        \"\"\"\n",
    "        Determine grammatical number\n",
    "        \"\"\"\n",
    "        word = self._remove_diacritics(word)\n",
    "        if any(word.endswith(m) for m in self.markers['dual_markers']):\n",
    "            return 'dual'\n",
    "        elif (any(word.endswith(m) for m in self.markers['plural_markers']['masculine']) or\n",
    "              any(word.endswith(m) for m in self.markers['plural_markers']['feminine'])):\n",
    "            return 'plural'\n",
    "        return 'singular'\n",
    "\n",
    "    def _determine_gender(self, word: str) -> str:\n",
    "        \"\"\"\n",
    "        Determine grammatical gender\n",
    "        \"\"\"\n",
    "        if any(word.endswith(m) for m in self.markers['feminine_markers']):\n",
    "            return 'feminine'\n",
    "        return 'masculine'\n",
    "\n",
    "    def _get_pattern(self, word: str) -> dict:\n",
    "        \"\"\"\n",
    "        Match word to morphological pattern\n",
    "        \"\"\"\n",
    "        for pattern_type, patterns in self.patterns.items():\n",
    "            for pattern, forms in patterns.items():\n",
    "                if self._matches_pattern(word, pattern):\n",
    "                    return {'type': pattern_type, 'pattern': pattern, 'forms': forms}\n",
    "        return None\n",
    "\n",
    "    def _matches_pattern(self, word: str, pattern: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if word matches given pattern\n",
    "        \"\"\"\n",
    "        word_clean = self._remove_diacritics(word)\n",
    "        pattern_clean = self._remove_diacritics(pattern)\n",
    "        \n",
    "        if len(word_clean) != len(pattern_clean):\n",
    "            return False\n",
    "            \n",
    "        root_positions = [i for i, char in enumerate(pattern_clean) if char in 'فعل']\n",
    "        return all(word_clean[i] == pattern_clean[i] for i in range(len(pattern_clean)) \n",
    "                  if i not in root_positions)\n",
    "\n",
    "    def _extract_root(self, word: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract root letters from word\n",
    "        \"\"\"\n",
    "        # Simplified root extraction\n",
    "        word = self._remove_diacritics(word)\n",
    "        # Remove common prefixes and suffixes\n",
    "        prefixes = ['است', 'ست', 'ان', 'ال', 'مت', 'مس', 'م']\n",
    "        suffixes = ['ون', 'ات', 'ان', 'ين', 'ة', 'ه', 'ي', 'ت']\n",
    "        \n",
    "        for prefix in prefixes:\n",
    "            if word.startswith(prefix):\n",
    "                word = word[len(prefix):]\n",
    "                break\n",
    "                \n",
    "        for suffix in suffixes:\n",
    "            if word.endswith(suffix):\n",
    "                word = word[:-len(suffix)]\n",
    "                break\n",
    "                \n",
    "        return word\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove_diacritics(text: str) -> str:\n",
    "        \"\"\"\n",
    "        Remove Arabic diacritical marks\n",
    "        \"\"\"\n",
    "        diacritics = ['َ', 'ُ', 'ِ', 'ّ', 'ْ', 'ً', 'ٌ', 'ٍ']\n",
    "        return ''.join(char for char in text if char not in diacritics)\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize_text(text: str) -> str:\n",
    "        \"\"\"\n",
    "        Normalize Arabic text\n",
    "        \"\"\"\n",
    "        text = text.strip()\n",
    "        return ''.join(char for char in text if char.isalnum() or char.isspace())\n",
    "\n",
    "    def _determine_analysis_type(self, words: list) -> str:\n",
    "        \"\"\"\n",
    "        Determine type of text being analyzed\n",
    "        \"\"\"\n",
    "        if len(words) == 0:\n",
    "            return 'empty'\n",
    "        elif len(words) == 1:\n",
    "            return 'word'\n",
    "        elif len(words) <= 3:\n",
    "            return 'phrase'\n",
    "        else:\n",
    "            return 'sentence'\n",
    "\n",
    "    def _get_position_marker(self, position: int, total_words: int) -> str:\n",
    "        \"\"\"\n",
    "        Get position marker for token\n",
    "        \"\"\"\n",
    "        if total_words == 1:\n",
    "            return self.position_markers['SINGLE']\n",
    "        elif position == 0:\n",
    "            return self.position_markers['START']\n",
    "        elif position == total_words - 1:\n",
    "            return self.position_markers['END']\n",
    "        return self.position_markers['MIDDLE']\n",
    "\n",
    "    def _determine_token_type(self, word: str) -> int:\n",
    "        \"\"\"\n",
    "        Determine token type\n",
    "        \"\"\"\n",
    "        if word.isdigit():\n",
    "            return self.token_types['NUMBER']\n",
    "        elif any(char in word for char in '،.؟!@#'):\n",
    "            return self.token_types['PUNCTUATION']\n",
    "        return self.token_types['WORD']\n",
    "\n",
    "    @staticmethod\n",
    "    def _has_diacritics(text: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if text contains diacritics\n",
    "        \"\"\"\n",
    "        diacritics = ['َ', 'ُ', 'ِ', 'ّ', 'ْ', 'ً', 'ٌ', 'ٍ']\n",
    "        return any(char in text for char in diacritics)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = UnifiedArabicAnalyzer()\n",
    "    \n",
    "    # Test different types of text\n",
    "    word = \"يَكْتُبُ\"\n",
    "    phrase = \"الكتابُ الجديدُ\"\n",
    "    sentence = \"كَتَبَ الطالبُ الدرسَ\"\n",
    "    \n",
    "    # Analyze each\n",
    "    word_analysis = analyzer.analyze(word)\n",
    "    phrase_analysis = analyzer.analyze(phrase)\n",
    "    sentence_analysis = analyzer.analyze(sentence)\n",
    "    \n",
    "    print(\"\\nWord Analysis:\")\n",
    "    print(word_analysis)\n",
    "    \n",
    "    print(\"\\nPhrase Analysis:\")\n",
    "    print(phrase_analysis)\n",
    "    \n",
    "    print(\"\\nSentence Analysis:\")\n",
    "    print(sentence_analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
